{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a9d4e7",
   "metadata": {},
   "source": [
    "# Problem Statement \n",
    "\n",
    "Sentiment analysis can help improve the performance of the recommendation system. Recommendation algorithm alone predicts the items based on user's past behaviour. However the recommend items might not be liked by the other users. By using sentiment analysis we can recommend the product based on how it's been percieved by other users. \n",
    "\n",
    "This notebook focuses on building a sentiment prediction model using various Machine Learning Algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ece8c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7fb3c99-25c7-48d4-b1ce-bc71c11f751f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "351694d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_from_file(module_name, file_path):\n",
    "    spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2e3ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = module_from_file(\"models\",\"models.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7b5e61",
   "metadata": {},
   "source": [
    "## Training the model using BOW Representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c411b0c-3fb2-4370-81e5-60a1610d31ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X=joblib.load('bow_features')\n",
    "#y= joblib.load('target')\n",
    "#X_transformed = X.toarray()\n",
    "#y= y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c8d5e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bow_model_.pkl','rb') as f:\n",
    "    bow_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a40dd3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized_review</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love album good hip hop current pop sound hype...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good flavor review collect promotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good flavor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>read review look buy couple lubricant ultimate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>husband buy gel gel cause irritation feel like...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   lemmatized_review  user_sentiment\n",
       "0  love album good hip hop current pop sound hype...               1\n",
       "1               good flavor review collect promotion               1\n",
       "2                                        good flavor               1\n",
       "3  read review look buy couple lubricant ultimate...               0\n",
       "4  husband buy gel gel cause irritation feel like...               0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/pre_process_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6517cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "170954d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['lemmatized_review']\n",
    "y=df['user_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "779e01ee-988a-4043-84aa-fc04e349985b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5d33efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming X_train to bow representation\n",
    "X_train=bow_model.fit_transform(X_train).toarray()\n",
    "X_test=bow_model.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cec2e6a",
   "metadata": {},
   "source": [
    "### Naive-Bayes without hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d57df26a-dc43-4957-b4b9-d0a085ff240d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 23:12:00,834 - root - INFO - Training the model without hyperparameter tuning\n",
      "2023-02-08 23:12:18,979 - root - INFO - Finished training at time.struct_time(tm_year=2023, tm_mon=2, tm_mday=8, tm_hour=17, tm_min=42, tm_sec=18, tm_wday=2, tm_yday=39, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "#training using naive bayes\n",
    "nb = models.NaiveBayes()\n",
    "naive_bayes,metrics=nb.train_model_without_hp(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d80a247-dcd8-4b66-ae63-fe3f845dcd84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_performance={}\n",
    "model_performance['naive_bayes_bow_without_hp']=metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd733ef",
   "metadata": {},
   "source": [
    "### Naive-bayes using hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "56ab7e54-e1b5-4c08-a78f-823d1a3ec45c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 23:17:14,513 - root - INFO - Started training naive bayes with hyperparameter tuning\n",
      "C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 20 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 749, in fit\n    X, y = self._check_X_y(X, y)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1203, in _check_X_y\n    X = binarize(X, threshold=self.binarize)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 2035, in binarize\n    cond = X > threshold\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 211. MiB for an array with shape (16796, 13171) and data type bool\n\n--------------------------------------------------------------------------------\n12 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 749, in fit\n    X, y = self._check_X_y(X, y)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1203, in _check_X_y\n    X = binarize(X, threshold=self.binarize)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 2035, in binarize\n    cond = X > threshold\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 211. MiB for an array with shape (16797, 13171) and data type bool\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 749, in fit\n    X, y = self._check_X_y(X, y)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1203, in _check_X_y\n    X = binarize(X, threshold=self.binarize)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 2025, in binarize\n    X = check_array(X, accept_sparse=[\"csr\", \"csc\"], copy=copy)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n    array = _asarray_with_order(\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n    return xp.asarray(array, copy=copy)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n    return numpy.array(x, copy=True, dtype=dtype)\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.65 GiB for an array with shape (16797, 13171) and data type float64\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m naive_bayes_hp,metrics\u001b[38;5;241m=\u001b[39m\u001b[43mnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model_with_hp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\EPGP-IIITB\\git repos\\Recommendation_System\\notebooks\\models.py:42\u001b[0m, in \u001b[0;36mNaiveBayes.train_model_with_hp\u001b[1;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     40\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarted training naive bayes with hyperparameter tuning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m random_cv \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(nb,cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,param_distributions\u001b[38;5;241m=\u001b[39mparam_grid)\n\u001b[1;32m---> 42\u001b[0m \u001b[43mrandom_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest params \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(random_cv\u001b[38;5;241m.\u001b[39mbest_params_))\n\u001b[0;32m     44\u001b[0m best_model \u001b[38;5;241m=\u001b[39m random_cv\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32m~\\flask\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\flask\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1768\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\flask\\lib\\site-packages\\sklearn\\model_selection\\_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    849\u001b[0m     )\n\u001b[1;32m--> 851\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\flask\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 20 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 749, in fit\n    X, y = self._check_X_y(X, y)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1203, in _check_X_y\n    X = binarize(X, threshold=self.binarize)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 2035, in binarize\n    cond = X > threshold\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 211. MiB for an array with shape (16796, 13171) and data type bool\n\n--------------------------------------------------------------------------------\n12 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 749, in fit\n    X, y = self._check_X_y(X, y)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1203, in _check_X_y\n    X = binarize(X, threshold=self.binarize)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 2035, in binarize\n    cond = X > threshold\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 211. MiB for an array with shape (16797, 13171) and data type bool\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 749, in fit\n    X, y = self._check_X_y(X, y)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1203, in _check_X_y\n    X = binarize(X, threshold=self.binarize)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 2025, in binarize\n    X = check_array(X, accept_sparse=[\"csr\", \"csc\"], copy=copy)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 950, in check_array\n    array = _asarray_with_order(\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 186, in _asarray_with_order\n    return xp.asarray(array, copy=copy)\n  File \"C:\\Users\\Rakshu\\flask\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 73, in asarray\n    return numpy.array(x, copy=True, dtype=dtype)\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.65 GiB for an array with shape (16797, 13171) and data type float64\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_hp,metrics=nb.train_model_with_hp(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27687511-72f6-4f5b-92f7-73c3196c681a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_performance['naive_bayes_bow_with_hp']=metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6012cec2",
   "metadata": {},
   "source": [
    "### Logistic Regression without hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78d71acb-f9cc-4ced-94b5-6d5b47e965fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 19:07:25,048 - root - INFO - Training the model without hyperparameter tuning\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2023-01-24 19:08:01,012 - root - INFO - Finished training at time.struct_time(tm_year=2023, tm_mon=1, tm_mday=24, tm_hour=19, tm_min=8, tm_sec=1, tm_wday=1, tm_yday=24, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "# training the model using logistic regression\n",
    "lr = LRClassification()\n",
    "lr_model,metrics = lr.train_model_without_hp(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cae00c3a-a25a-4009-baec-e88c4af9fd9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08e8dc23-b3a0-4387-bf82-ca6196adfc8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_performance['lr_bow_without_hp']=metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b3be4e",
   "metadata": {},
   "source": [
    "### Logistic regression with hyper parameter tuning \n",
    "\n",
    "Training logistic regression with hyper-parameter tuning using randomSearchCV on a smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e82309-a5d2-401c-83f9-dccb56a30db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning the model with smaller set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78dbe11a-3f25-442f-aeda-257eecb3b96d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 19:13:42,820 - root - INFO - Started training logistic regression with hyperparameter tuning\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "2023-01-24 19:21:25,115 - root - INFO - Best params {'tol': 0.01, 'C': 1} \n",
      "2023-01-24 19:21:42,178 - root - INFO - Finished training at time.struct_time(tm_year=2023, tm_mon=1, tm_mday=24, tm_hour=19, tm_min=21, tm_sec=42, tm_wday=1, tm_yday=24, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "lr_model_hp,metrics = lr.train_model_with_hp(X_train[0:10000],y_train[0:10000],X_test[0:100],y_test[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc25cc75-c04c-4eb9-850f-dfd45981211d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_performance['lr_bow_with_hp']=metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49cf0cd5-8033-4a75-9b27-00ea20347427",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'naive_bayes_bow_without_hp': {'training_accuracy': 0.8917567503214439,\n",
       "  'training_precision': 0.911524500907441,\n",
       "  'training_recall': 0.9721490402709823,\n",
       "  'test_accuracy': 0.8728888888888889,\n",
       "  'test_precision': 0.9076813824121198,\n",
       "  'test_recall': 0.954686916469563},\n",
       " 'naive_bayes_bow_with_hp': {'training_accuracy': 0.963141101957236,\n",
       "  'training_precision': 0.9991598991879026,\n",
       "  'training_recall': 0.959191354373891,\n",
       "  'test_accuracy': 0.9263333333333333,\n",
       "  'test_precision': 0.9846133613887428,\n",
       "  'test_recall': 0.9320303747043446},\n",
       " 'lr_bow_with_hp': {'training_accuracy': 0.9675,\n",
       "  'training_precision': 0.9994130766521893,\n",
       "  'training_recall': 0.9637763187683949,\n",
       "  'test_accuracy': 0.9,\n",
       "  'test_precision': 0.9655172413793104,\n",
       "  'test_recall': 0.9230769230769231}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe2a46",
   "metadata": {},
   "source": [
    "### XGboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2061c694-4445-4fcd-84e5-52344aa32f40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 19:23:59,636 - root - INFO - Training the model without hyperparameter tuning\n",
      "2023-01-24 19:32:00,792 - root - INFO - Finished training at time.struct_time(tm_year=2023, tm_mon=1, tm_mday=24, tm_hour=19, tm_min=32, tm_sec=0, tm_wday=1, tm_yday=24, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBoost()\n",
    "xgb,metrics=xgb.train_model_without_hp(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91a6a046-1c2d-4e6e-948f-28c4ac75fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance['xgb_without_hp'] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ad596",
   "metadata": {},
   "source": [
    "### Evaluating performance of different ML algorithms trained on BOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daac57a9-9d27-4170-999d-093994528ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive_bayes_bow_without_hp</th>\n",
       "      <th>naive_bayes_bow_with_hp</th>\n",
       "      <th>lr_bow_with_hp</th>\n",
       "      <th>xgb_without_hp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training_accuracy</th>\n",
       "      <td>0.891757</td>\n",
       "      <td>0.963141</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>0.954950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_precision</th>\n",
       "      <td>0.911525</td>\n",
       "      <td>0.999160</td>\n",
       "      <td>0.999413</td>\n",
       "      <td>0.971023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_recall</th>\n",
       "      <td>0.972149</td>\n",
       "      <td>0.959191</td>\n",
       "      <td>0.963776</td>\n",
       "      <td>0.978332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.872889</td>\n",
       "      <td>0.926333</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.937556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.907681</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.959528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.954687</td>\n",
       "      <td>0.932030</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.970995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    naive_bayes_bow_without_hp  naive_bayes_bow_with_hp  \\\n",
       "training_accuracy                     0.891757                 0.963141   \n",
       "training_precision                    0.911525                 0.999160   \n",
       "training_recall                       0.972149                 0.959191   \n",
       "test_accuracy                         0.872889                 0.926333   \n",
       "test_precision                        0.907681                 0.984613   \n",
       "test_recall                           0.954687                 0.932030   \n",
       "\n",
       "                    lr_bow_with_hp  xgb_without_hp  \n",
       "training_accuracy         0.967500        0.954950  \n",
       "training_precision        0.999413        0.971023  \n",
       "training_recall           0.963776        0.978332  \n",
       "test_accuracy             0.900000        0.937556  \n",
       "test_precision            0.965517        0.959528  \n",
       "test_recall               0.923077        0.970995  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bow_performance=pd.DataFrame(model_performance)\n",
    "bow_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355ea5a0-61f1-4bd5-a31e-a34b282a3a67",
   "metadata": {},
   "source": [
    "## Training the model using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e865d02-d2e2-47a9-b46e-bf5631e26dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=joblib.load('tf_idf_features')\n",
    "#y= joblib.load('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6787631b-d916-4045-b0ce-27ec7238aa5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42a2a2e",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9c6ac25-e3e9-4c47-8f6f-2e5ae2a64a9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 19:35:30,070 - root - INFO - Training the model without hyperparameter tuning\n",
      "2023-01-24 19:35:37,090 - root - INFO - Finished training at time.struct_time(tm_year=2023, tm_mon=1, tm_mday=24, tm_hour=19, tm_min=35, tm_sec=37, tm_wday=1, tm_yday=24, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "#training using naive bayes\n",
    "nb = NaiveBayes()\n",
    "naive_bayes,metrics=nb.train_model_without_hp(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54cbade0-56e0-458d-83dc-0449829c249c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_performance={}\n",
    "model_performance['naive_bayes_without_hp'] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f808a7d-9017-48be-ba88-f03c8ad066ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 19:44:12,575 - root - INFO - Started training naive bayes with hyperparameter tuning\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "2023-01-24 19:45:33,938 - root - INFO - Best params {'alpha': 1e-07} \n",
      "2023-01-24 19:45:41,024 - root - INFO - Finished training at time.struct_time(tm_year=2023, tm_mon=1, tm_mday=24, tm_hour=19, tm_min=45, tm_sec=41, tm_wday=1, tm_yday=24, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_hp,metrics=nb.train_model_with_hp(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "287f7427-645b-4e3a-8f20-cbcbbbf2f89b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_performance['naive_bayes_bow_with_hp']=metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6975266",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0f88a98-05a9-44b8-b060-e97200e2fe11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 19:48:17,707 - root - INFO - Training the model without hyperparameter tuning\n",
      "2023-01-24 19:48:50,442 - root - INFO - Finished training at time.struct_time(tm_year=2023, tm_mon=1, tm_mday=24, tm_hour=19, tm_min=48, tm_sec=50, tm_wday=1, tm_yday=24, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "# training the model using logistic regression\n",
    "lr = LRClassification()\n",
    "lr_model,metrics = lr.train_model_without_hp(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e807d9a3-f675-42a4-9ee7-0e3053543e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_performance['lr_bow_without_hp']=metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09c41f6d-9b39-4219-80e7-a4be0b62c587",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 19:50:39,685 - root - INFO - Started training logistic regression with hyperparameter tuning\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "2023-01-24 19:56:22,838 - root - INFO - Best params {'tol': 0.01, 'C': 1} \n",
      "2023-01-24 19:56:37,276 - root - INFO - Finished training at time.struct_time(tm_year=2023, tm_mon=1, tm_mday=24, tm_hour=19, tm_min=56, tm_sec=37, tm_wday=1, tm_yday=24, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "lr_model_hp,metrics = lr.train_model_with_hp(X_train[0:10000],y_train[0:10000],X_test[0:100],y_test[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97047e6f-086a-45e6-a85d-23e36d068061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_performance['lr_bow_with_hp']=metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca338e0",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a26bed89-aa1c-4804-aef3-f0e6f50bce4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 19:56:50,450 - root - INFO - Training the model without hyperparameter tuning\n",
      "2023-01-24 20:05:06,424 - root - INFO - Finished training at time.struct_time(tm_year=2023, tm_mon=1, tm_mday=24, tm_hour=20, tm_min=5, tm_sec=6, tm_wday=1, tm_yday=24, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "xgbc = XGBoost()\n",
    "xgb,metrics=xgbc.train_model_without_hp(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6c4cdac-8009-4004-b690-1b7b3bd09793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_performance['xgb_without_hp'] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a25581d7-2daa-47a5-b8ba-2f01977a44c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'naive_bayes_without_hp': {'training_accuracy': 0.922805847897519,\n",
       "  'training_precision': 0.998122286116653,\n",
       "  'training_recall': 0.9145652992096349,\n",
       "  'test_accuracy': 0.9026666666666666,\n",
       "  'test_precision': 0.9887993443518645,\n",
       "  'test_recall': 0.901157724386904},\n",
       " 'naive_bayes_bow_with_hp': {'training_accuracy': 0.9521405781227678,\n",
       "  'training_precision': 0.9705787953354017,\n",
       "  'training_recall': 0.9755363191569439,\n",
       "  'test_accuracy': 0.8918888888888888,\n",
       "  'test_precision': 0.9279825412221144,\n",
       "  'test_recall': 0.9528196190713307},\n",
       " 'lr_bow_without_hp': {'training_accuracy': 0.922805847897519,\n",
       "  'training_precision': 0.998122286116653,\n",
       "  'training_recall': 0.9145652992096349,\n",
       "  'test_accuracy': 0.9026666666666666,\n",
       "  'test_precision': 0.9887993443518645,\n",
       "  'test_recall': 0.901157724386904},\n",
       " 'lr_bow_with_hp': {'training_accuracy': 0.9234,\n",
       "  'training_precision': 0.9985170538803757,\n",
       "  'training_recall': 0.9146479510980303,\n",
       "  'test_accuracy': 0.93,\n",
       "  'test_precision': 1.0,\n",
       "  'test_recall': 0.9230769230769231},\n",
       " 'xgb_without_hp': {'training_accuracy': 0.9784751654840707,\n",
       "  'training_precision': 0.986227962059911,\n",
       "  'training_recall': 0.9895155653529759,\n",
       "  'test_accuracy': 0.9534444444444444,\n",
       "  'test_precision': 0.9664297966184758,\n",
       "  'test_recall': 0.9819494584837545}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d14a5597-bab2-464e-b631-715271a84e91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xbgoost without hyperparameter\n",
    "import pickle\n",
    "with open('model.pkl','wb') as f:\n",
    "    pickle.dump(xgb,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a42a9a3-70a4-4060-94e8-d88898a6bcc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_idf_performance=pd.DataFrame(model_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9134865d",
   "metadata": {},
   "source": [
    "## Evaluating the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54eceaf0-bc90-4409-a89a-48ee2b595cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive_bayes_without_hp</th>\n",
       "      <th>naive_bayes_bow_with_hp</th>\n",
       "      <th>lr_bow_without_hp</th>\n",
       "      <th>lr_bow_with_hp</th>\n",
       "      <th>xgb_without_hp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training_accuracy</th>\n",
       "      <td>0.922806</td>\n",
       "      <td>0.952141</td>\n",
       "      <td>0.922806</td>\n",
       "      <td>0.923400</td>\n",
       "      <td>0.978475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_precision</th>\n",
       "      <td>0.998122</td>\n",
       "      <td>0.970579</td>\n",
       "      <td>0.998122</td>\n",
       "      <td>0.998517</td>\n",
       "      <td>0.986228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_recall</th>\n",
       "      <td>0.914565</td>\n",
       "      <td>0.975536</td>\n",
       "      <td>0.914565</td>\n",
       "      <td>0.914648</td>\n",
       "      <td>0.989516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.902667</td>\n",
       "      <td>0.891889</td>\n",
       "      <td>0.902667</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.953444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.988799</td>\n",
       "      <td>0.927983</td>\n",
       "      <td>0.988799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.901158</td>\n",
       "      <td>0.952820</td>\n",
       "      <td>0.901158</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.981949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    naive_bayes_without_hp  naive_bayes_bow_with_hp  \\\n",
       "training_accuracy                 0.922806                 0.952141   \n",
       "training_precision                0.998122                 0.970579   \n",
       "training_recall                   0.914565                 0.975536   \n",
       "test_accuracy                     0.902667                 0.891889   \n",
       "test_precision                    0.988799                 0.927983   \n",
       "test_recall                       0.901158                 0.952820   \n",
       "\n",
       "                    lr_bow_without_hp  lr_bow_with_hp  xgb_without_hp  \n",
       "training_accuracy            0.922806        0.923400        0.978475  \n",
       "training_precision           0.998122        0.998517        0.986228  \n",
       "training_recall              0.914565        0.914648        0.989516  \n",
       "test_accuracy                0.902667        0.930000        0.953444  \n",
       "test_precision               0.988799        1.000000        0.966430  \n",
       "test_recall                  0.901158        0.923077        0.981949  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_performance"
   ]
  }
 ],
 "metadata": {
  "forced_instance_type": "ml.t3.medium",
  "forced_lcc_arn": "",
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "flask",
   "language": "python",
   "name": "flask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
